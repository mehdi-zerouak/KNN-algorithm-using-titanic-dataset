{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2d8da00-bae3-4853-aee5-4f4f40e6e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP 01 - MACHINE LEARNING - MAHDI ZEROUAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "821b4d2e-08a7-4bec-9b1e-4224c8bae172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    str    \n",
      " 4   Sex          891 non-null    str    \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    str    \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    str    \n",
      " 11  Embarked     889 non-null    str    \n",
      "dtypes: float64(2), int64(5), str(5)\n",
      "memory usage: 83.7 KB\n"
     ]
    }
   ],
   "source": [
    "# --------------- STEP 1 - LOAD DATA --------------- \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load data into data variable\n",
    "data = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "# print data info\n",
    "data.info()\n",
    "# ----- BTW --------- (definition of each variable)\n",
    "# ** Survived = target variable ** (0 = did not survive) (1 = survived)\n",
    "# Pclass = ticket class (1st class, 2nd class...etc)\n",
    "# SibSp = Number of siblings/spouses aboard\n",
    "# Parch = Number of parents/children aboard\n",
    "# Fare = ticket price\n",
    "# Embarked = Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "\n",
    "# PassangerID, Name, Sex, Ticket, Cabin, Age are obvious\n",
    "# --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80a099a8-6ca7-47b6-a35a-1d4d191618a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 5 first rows (sample) of our dataset\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c587f5d-de5d-43d5-aa9e-f7b66a236f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------  STEP 2 - PREPROCESS THE DATA --------------- \n",
    "\n",
    "# since we have many unnecessary columns we're going to delete them from our data variable that contains the dataset\n",
    "# columns that we don't need in our KNN model are [PassengerId, Name, Ticket, Cabin] because they're either just identifiers or text\n",
    "data = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326dfe38-a6a2-4192-a287-fa84dc2fd105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some values are not numbers so we can't compute distance between them (example in sex: male, female)\n",
    "# solution is to convert these values to numbers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# we have two types of enconding\n",
    "\n",
    "# 1 - label encoding for binary variables like sex: if male then 1 else if female then 0\n",
    "\n",
    "# 2 - one hot encoding for variables with more than 2 categories, we going to create a new column for each category\n",
    "# then assign value 1 if the row belongs to that category, else 0\n",
    "\n",
    "# label encoding for \"sex\" \n",
    "# (1 for male and 0 for female)\n",
    "le = LabelEncoder()\n",
    "data['Sex'] = le.fit_transform(data['Sex'])\n",
    "\n",
    "# One-hot encoding for \"embarked\"\n",
    "# since we have 3 categories, we will create 3 columns\n",
    "data = pd.get_dummies(data, columns=['Embarked'], dtype=int)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc0877-2e5c-4818-b8b1-e6195b1f4103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many null values we have in our dataset\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22dfa0-9afd-4a2d-a5ed-6e908ba5252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 177 missed value in age\n",
    "\n",
    "# we are going to fill them with a median of ages in our dataset\n",
    "data['Age'] = data['Age'].fillna(data['Age'].median())\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d11c9c-0145-45cb-aa26-5649904d3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------  STEP 3 - SPLIT DATA --------------- \n",
    "\n",
    "# 70% train, 30% test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data.drop('Survived', axis=1) \n",
    "y = data['Survived']\n",
    "\n",
    "# split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y,\n",
    "    test_size=0.3, # means 30% test and 70% train\n",
    "    random_state=42, # if we don't specify random_state, each time we run the notebook we will get a different split\n",
    "                     # which means different test/train data, different accuracy\n",
    "    stratify=y # since only 38% survived our dataset is imbalanced, \n",
    "                # stratify=y will ensure test/train data will be splitted more reliably, not in a random way\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b60109c-3e1f-4d52-bacf-1dd85283b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------  GOING BACK TO STEP 2 - PREPROCESS THE DATA  --------------- \n",
    "\n",
    "# scales numeric features\n",
    "\n",
    "# since KNN usually use Euclidean distance\n",
    "# we have to scale because If one feature has a much larger scale (like Fare), it will dominate other variables when calculating\n",
    "# which means the feature with the largest numeric range controls the model which is not logical \n",
    "# scaling ensures that all features contribute equally\n",
    "\n",
    "# we will not touch binary variables like sex or embarked_c, embarked_q...etc because they can be only 0 or 1\n",
    "\n",
    "# why we're back to step 2 after finishing with step 3 :\n",
    "# if we scale on the whole dataset before splitting the data, the scaler can learn the mean of the entire dataset or some other stuff\n",
    "# that includes our future test data, which is some kind of data leakage\n",
    "# so CHATGPT said split the data before scaling it, then scale \n",
    "\n",
    "\n",
    "# in our case we will scale ('Age', 'Fare', 'SibSp', 'Parch')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scaling on train data\n",
    "# fit_transform(): calculates mean/std AND immediately scales the same data (used in train data)\n",
    "x_train[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']] = scaler.fit_transform(x_train[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']])\n",
    "\n",
    "# scaling on test data\n",
    "# transform() does NOT recalculate mean/std â€” it reuses the ones learned during fit_transform() (used in test data)\n",
    "x_test[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']] = scaler.transform(x_test[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']])\n",
    "\n",
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff600d80-9151-473a-a606-c62683ad77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------  STEP 4 - TRAIN THE MODEL --------------- \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create KNN model\n",
    "# K = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa9b5a-df72-470f-b1e0-13fe01d2d5b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157fc3a-d898-47bc-b466-74e62569996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels for test set\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "# quick look at first 10 predictions\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08206615-286d-4097-a8ee-876a41e13f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------  STEP 5 - EVALUATE THE DATA --------------- \n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# detailed report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf7900-04f4-46e1-852d-09a65cc8e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
